name: Nightly Thought Processing

on:
  # Schedule: Run at 2 AM UTC daily
  schedule:
    - cron: '0 2 * * *'

  # Allow manual triggering
  workflow_dispatch:
    inputs:
      force_synthesis:
        description: 'Force weekly synthesis generation'
        required: false
        type: boolean
        default: false

jobs:
  process-thoughts:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run batch processor
        env:
          # Supabase credentials
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}

          # AI API keys
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

          # Model configuration
          CLAUDE_MODEL: ${{ vars.CLAUDE_MODEL || 'claude-sonnet-4-20250514' }}
          CLAUDE_MAX_TOKENS: ${{ vars.CLAUDE_MAX_TOKENS || '4000' }}
          EMBEDDING_MODEL: ${{ vars.EMBEDDING_MODEL || 'text-embedding-3-small' }}
          EMBEDDING_DIMENSIONS: ${{ vars.EMBEDDING_DIMENSIONS || '1536' }}

          # Caching configuration
          SEMANTIC_CACHE_THRESHOLD: ${{ vars.SEMANTIC_CACHE_THRESHOLD || '0.92' }}
          SEMANTIC_CACHE_TTL_DAYS: ${{ vars.SEMANTIC_CACHE_TTL_DAYS || '7' }}
          PROMPT_CACHE_ENABLED: ${{ vars.PROMPT_CACHE_ENABLED || 'true' }}

          # Processing configuration
          RATE_LIMIT_DELAY: ${{ vars.RATE_LIMIT_DELAY || '0.5' }}
          MAX_RETRIES: ${{ vars.MAX_RETRIES || '3' }}

          # Logging
          LOG_LEVEL: ${{ vars.LOG_LEVEL || 'INFO' }}

        run: |
          cd batch_processor
          python processor.py

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: batch-processor-logs-${{ github.run_number }}
          path: batch_processor/logs/
          retention-days: 30

      - name: Notify on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '‚ùå Batch Processing Failed',
              body: `
                Batch processing workflow failed.

                **Run ID:** ${{ github.run_id }}
                **Run Number:** ${{ github.run_number }}
                **Triggered by:** ${{ github.event_name }}
                **Time:** ${{ github.event.head_commit.timestamp }}

                [View logs](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
              `,
              labels: ['automation', 'bug']
            })

  # Optional: Weekly synthesis job (Sundays only)
  weekly-synthesis:
    runs-on: ubuntu-latest
    # Only run on Sundays
    if: github.event.schedule == '0 3 * * 0' || github.event.inputs.force_synthesis == 'true'
    needs: process-thoughts
    timeout-minutes: 15

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Generate weekly synthesis
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          cd batch_processor
          python -c "
          import asyncio
          from processor import BatchThoughtProcessor

          async def run_synthesis():
              processor = BatchThoughtProcessor()
              # Get all users and generate synthesis for each
              users = processor.supabase.table('users').select('id').execute()
              for user in users.data:
                  await processor.generate_weekly_synthesis(user['id'])

          asyncio.run(run_synthesis())
          "

      - name: Upload synthesis logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: synthesis-logs-${{ github.run_number }}
          path: batch_processor/logs/
          retention-days: 30
